{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "from utils_data.synthetic_ts import generate_ts_data, generate_ts_panel\n",
    "from utils_visualization import plot_residuals_outliers\n",
    "\n",
    "\n",
    "class OnlineMovingAverage:\n",
    "    def __init__(self, window_size):\n",
    "        self._window_size = window_size\n",
    "        self._array = np.array([None] * window_size)\n",
    "        self._sum = 0\n",
    "    \n",
    "    def fit(self, y_init):\n",
    "        assert len(y_init)==self._window_size\n",
    "        self._array = y_init\n",
    "        self._sum = np.sum(y_init)\n",
    "        self.fitted = True\n",
    "    \n",
    "    def predict(self, h):\n",
    "        assert self.fitted\n",
    "        y_hat = np.repeat(self._sum/len(self._array), h) \n",
    "        return y_hat\n",
    "        \n",
    "    def update(self, val):\n",
    "        self._array = np.roll(self._array, -1)\n",
    "        self._sum += val\n",
    "        self._sum -= self._array[-1]\n",
    "        self._array[-1] = val\n",
    "\n",
    "def rolling_window(Model, y, window_size):    \n",
    "    model = Model(window_size)\n",
    "    model.fit(y[:window_size])\n",
    "    \n",
    "    n_dates = len(y)\n",
    "    y_hat = np.ones(n_dates) * 10000\n",
    "    residuals = np.ones(n_dates) * 10000\n",
    "    for idx, val in enumerate(y):\n",
    "        val_hat = model.predict(1)\n",
    "        model.update(val)\n",
    "        residuals[idx] = val-val_hat\n",
    "        y_hat[idx] = val_hat\n",
    "    \n",
    "    return y_hat\n",
    "\n",
    "def normalize(x):\n",
    "    # drop min-max observations for robustness\n",
    "    x_r = x.copy()\n",
    "    x_r.sort()\n",
    "    x_r = x_r[1:-1]\n",
    "    \n",
    "    x_norm = x-np.mean(x_r)\n",
    "    x_norm /= np.std(x_r)\n",
    "    return x_norm\n",
    "\n",
    "def simple_outlier_detection(x, empirical=False):\n",
    "    score = normalize(x)\n",
    "    if empirical:\n",
    "        q0, q1 = np.quantile(x_norm, q=[0.001,0.999], interpolation='linear')\n",
    "    else:\n",
    "        q0, q1 = norm.ppf([0.001, 0.999])\n",
    "        \n",
    "    outlier = np.logical_not((score > q0) & (score < q1))\n",
    "    threshold = [q0, q1]\n",
    "    return outlier, score, threshold\n",
    "\n",
    "def panel_outlier_detection(panel_df, empirical=False):    \n",
    "    df_dict = {'u_id': [], 'y_hat': [], 'outlier': [], 'outlier_score': []}\n",
    "    for u_id in panel_df.u_id.unique():\n",
    "        print(\"========= u_id: {} =========\".format(u_id))\n",
    "        ts = panel_df.loc[panel_df['u_id']==u_id]\n",
    "        \n",
    "        y = panel_df.loc[u_id,'y']\n",
    "        y_hat = rolling_window(Model=OnlineMovingAverage, y=y, window_size=5)\n",
    "        \n",
    "        residuals = y-y_hat\n",
    "        outlier, outlier_score, _ = simple_outlier_detection(residuals, empirical=empirical)\n",
    "        \n",
    "        df_dict['u_id'].append(u_id)\n",
    "        df_dict['y_hat'].append(y_hat)\n",
    "        df_dict['outlier'].append(outlier)\n",
    "        df_dict['outlier_score'].append(outlier_score)\n",
    "    \n",
    "    outlier_df = pd.DataFrame.from_dict(df_dict)\n",
    "    panel_df = panel_df.merge(outlier_df, on='u_id', how='left')\n",
    "    return panel_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _, _ = generate_ts_data(n_dates=10, seed=2)\n",
    "y_hat = rolling_window(OnlineMovingAverage, y, window_size=5)\n",
    "residuals = y-y_hat\n",
    "outlier, outlier_score, threshold = simple_outlier_detection(residuals, empirical=False)\n",
    "plot_residuals_outliers(y, y_hat, outlier, outlier_score, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= u_id: 0 =========\n",
      "========= u_id: 1 =========\n",
      "========= u_id: 2 =========\n",
      "========= u_id: 3 =========\n",
      "========= u_id: 4 =========\n",
      "========= u_id: 5 =========\n",
      "========= u_id: 6 =========\n",
      "========= u_id: 7 =========\n",
      "========= u_id: 8 =========\n",
      "========= u_id: 9 =========\n"
     ]
    }
   ],
   "source": [
    "panel_df = generate_ts_panel(n_u_id=10, n_dates = 20)\n",
    "panel_df = panel_outlier_detection(panel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_id = 0\n",
    "y = panel_df.loc[0,'y']\n",
    "y_hat = panel_df.loc[0,'y_hat']\n",
    "outlier = panel_df.loc[0,'outlier']\n",
    "outlier_score = panel_df.loc[0,'outlier_score']\n",
    "plot_residuals_outliers(y, y_hat, outlier, outlier_score, threshold=norm.ppf([0.001, 0.999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_visualization import plot_mixtures\n",
    "from utils_data.synthetic_mixtures import generate_mixtures\n",
    "\n",
    "mixtures_df = generate_mixtures()\n",
    "plot_mixtures(mixtures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ocsmm import OneClassSMM\n",
    "\n",
    "Strain = mixtures_df['distribution'].tolist()\n",
    "\n",
    "clf = OneClassSMM(C=0.1, gamma=0.1)\n",
    "clf.fit(Strain)\n",
    "\n",
    "# y_pred_train = clf.predict(X_train)\n",
    "# y_pred_test = clf.predict(X_test)\n",
    "# y_pred_outliers = clf.predict(X_outliers)\n",
    "# n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "# n_error_test = y_pred_test[y_pred_test == -1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mixtures_df['distribution']\", type(mixtures_df['distribution']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Strain = mixtures_df['distribution'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
